{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データクレンジング\n",
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "combine = [train_df, test_df]\n",
    "\n",
    "train_df=train_df.drop(['Ticket','Cabin'],axis=1)\n",
    "test_df=test_df.drop(['Ticket','Cabin'],axis=1)\n",
    "combine=[train_df,test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    #正規表現のパターンで分割するstr.extract,expand=Trueだとpandas.DataFrame [A-Za-z]１桁以上の半角英（a～z、A～Z）にマッチ\n",
    "    dataset['Title']=dataset.Name.str.extract('([A-Za-z]+)\\.',expand=False)\n",
    "\n",
    "for dataset in combine:\n",
    "    #要素の値を置換するには、replace()\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "title_mapping={'Mr':1,'Miss':2,\"Mrs\":3,'Master':4,'Rare':5}\n",
    "for dataset in combine:\n",
    "    #map(\"A\":\"B\")でAをBに入れ替える。\n",
    "    dataset['Title']=dataset['Title'].map(title_mapping)\n",
    "    #fillna欠損値を他の値に置換\n",
    "    dataset['Title']=dataset['Title'].fillna(0)\n",
    "\n",
    "train_df=train_df.drop(['Name','PassengerId'],axis=1)\n",
    "test_df=test_df.drop(['Name','PassengerId'],axis=1)\n",
    "combine=[train_df,test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Sex']=dataset['Sex'].map({'female':1,'male':0}).astype(int)\n",
    "\n",
    "guess_ages=np.zeros((2,3))\n",
    "for dataset in combine:\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,3):\n",
    "            #欠損値を除外dropna\n",
    "            guess_df=dataset[(dataset['Sex']==i)& (dataset['Pclass']==j+1)]['Age'].dropna()\n",
    "            #median中央値\n",
    "            age_guess=guess_df.median()\n",
    "            guess_ages[i,j]=int(age_guess/0.5+0.5)*0.5\n",
    "        \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 3):\n",
    "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "train_df['AgeBand']=pd.cut(train_df['Age'],5)\n",
    "test_df['AgeBand']=pd.cut(test_df['Age'],5)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Age']<=16,'Age']=0\n",
    "    dataset.loc[(dataset['Age']>16)&(dataset['Age']<=32),'Age']=1\n",
    "    dataset.loc[(dataset['Age']>32)&(dataset['Age']<=48),'Age']=2\n",
    "    dataset.loc[(dataset['Age']>48)&(dataset['Age']<=64),'Age']=3\n",
    "    dataset.loc[dataset['Age']>64,'Age']=4\n",
    "    \n",
    "train_df=train_df.drop(['AgeBand'],axis=1)\n",
    "test_df=test_df.drop(['AgeBand'],axis=1)\n",
    "combine=[train_df,test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['IsAlone']=0\n",
    "    dataset.loc[dataset['FamilySize']==1,'IsAlone']=1\n",
    "\n",
    "train_df=train_df.drop(['Parch','SibSp','FamilySize'],axis=1)\n",
    "test_df=test_df.drop(['Parch','SibSp','FamilySize'],axis=1)\n",
    "combine=[train_df,test_df]\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset['Age*Class']=dataset.Age*dataset.Pclass\n",
    "    \n",
    "freq_port=train_df.Embarked.dropna().mode()[0]\n",
    "for dataset in combine:\n",
    "    #欠損値を他の値に置換（穴埋め）するにはfillna()\n",
    "    dataset['Embarked']=dataset['Embarked'].fillna(freq_port)\n",
    "    \n",
    "for dataset in combine:\n",
    "    dataset['Embarked']=dataset['Embarked'].map({'S':0,'C':1,'Q':2}).astype(int)\n",
    "\n",
    "test_df['Fare'].fillna(test_df['Fare'].dropna().median(),inplace=True)\n",
    "train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\n",
    "\n",
    "for dataset in combine:\n",
    "    dataset.loc[dataset['Fare']<=7.91,'Fare']=0\n",
    "    dataset.loc[(dataset['Fare']>7.91)&(dataset['Fare']<=14.454),'Fare']=1\n",
    "    dataset.loc[(dataset['Fare']>14.454)&(dataset['Fare']<=31.0),'Fare']=2\n",
    "    dataset.loc[dataset['Fare']>31.0,'Fare']=3\n",
    "    dataset['Fare']=dataset['Fare'].astype(int)\n",
    "    \n",
    "train_df=train_df.drop(['FareBand'],axis=1)\n",
    "combine=[train_df,test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 8), (891,), (418, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=train_df.drop(\"Survived\",axis=1)\n",
    "y_train=train_df[\"Survived\"]\n",
    "x_test=test_df.copy()\n",
    "\n",
    "\n",
    "x_train.shape, y_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.26"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg=LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "y_pred=logreg.predict(x_test)\n",
    "acc_logreg=round(logreg.score(x_train,y_train)*100,2)\n",
    "acc_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sex</td>\n",
       "      <td>2.200978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Title</td>\n",
       "      <td>0.414362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>0.281026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IsAlone</td>\n",
       "      <td>0.262084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fare</td>\n",
       "      <td>-0.022062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Age*Class</td>\n",
       "      <td>-0.085959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.371647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>-1.083515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature  Correlation\n",
       "1        Sex     2.200978\n",
       "5      Title     0.414362\n",
       "4   Embarked     0.281026\n",
       "6    IsAlone     0.262084\n",
       "3       Fare    -0.022062\n",
       "7  Age*Class    -0.085959\n",
       "2        Age    -0.371647\n",
       "0     Pclass    -1.083515"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df=pd.DataFrame(train_df.columns.delete(0))\n",
    "coeff_df.columns=['Feature']\n",
    "#model.coef_  #回帰変数の表示\n",
    "coeff_df['Correlation']=pd.Series(logreg.coef_[0])\n",
    "coeff_df.sort_values(by='Correlation',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred=svc.predict(x_test)\n",
    "acc_svc=round(svc.score(x_train,y_train)*100,2)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.06"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "acc_knn=round(knn.score(x_train,y_train)*100,2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.88"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian=GaussianNB()\n",
    "gaussian.fit(x_train,y_train)\n",
    "y_pred=gaussian.predict(x_test)\n",
    "acc_gaussian=round(gaussian.score(x_train,y_train)*100,2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.79"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron=Perceptron()\n",
    "perceptron.fit(x_train,y_train)\n",
    "y_pred=perceptron.predict(x_test)\n",
    "acc_perceptron=round(perceptron.score(x_train,y_train)*100,2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.46"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svc=LinearSVC()\n",
    "linear_svc.fit(x_train,y_train)\n",
    "y_pred=linear_svc.predict(x_test)\n",
    "acc_linear_svc=round(linear_svc.score(x_train,y_train)*100,2)\n",
    "acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.44"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train, y_train)\n",
    "y_pred = sgd.predict(x_test)\n",
    "acc_sgd = round(sgd.score(x_train, y_train) * 100, 2)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree=DecisionTreeClassifier()\n",
    "decision_tree.fit(x_train, y_train)\n",
    "y_decision_tree = decision_tree.predict(x_test)\n",
    "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest=RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(x_train,y_train)\n",
    "y_pred=random_forest.predict(x_test)\n",
    "acc_random_forest=round(random_forest.score(x_train,y_train)*100,2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>86.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>86.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>84.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>83.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>81.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>79.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>78.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "      <td>77.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>76.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  Score\n",
       "3               Random Forest  86.64\n",
       "8               Decision Tree  86.64\n",
       "1                         KNN  84.06\n",
       "0     Support Vector Machines  83.50\n",
       "2         Logistic Regression  81.26\n",
       "7                  Linear SVC  79.46\n",
       "5                  Perceptron  78.79\n",
       "6  Stochastic Gradient Decent  77.44\n",
       "4                 Naive Bayes  76.88"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', 'Linear SVC', \n",
    "              'Decision Tree'],\n",
    "    'Score':[acc_svc, acc_knn, acc_logreg, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
    "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
    "models.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\nsats\\Anaconda3\\envs\\gpu-env\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    }
   ],
   "source": [
    "grid_n_estimator = [10, 50, 100, 300]\n",
    "grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "grid_criterion = ['gini', 'entropy']\n",
    "grid_seed = [0]\n",
    "param_grid={            #RandomForestClassifier - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "            'n_estimators': grid_n_estimator, #default=10\n",
    "            'criterion': grid_criterion, #default=”gini”\n",
    "            'max_depth': grid_max_depth, #default=None\n",
    "            'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n",
    "            'random_state': grid_seed\n",
    "             }\n",
    "from sklearn import model_selection\n",
    "tune_model=model_selection.GridSearchCV(RandomForestClassifier(),param_grid=param_grid,scoring='roc_auc',verbose=0)\n",
    "tune_model.fit(x_train,y_train)\n",
    "y_pred=tune_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('../input/test.csv')\n",
    "submission=pd.DataFrame({\n",
    "    'PassengerId':test_df['PassengerId'],\n",
    "    'Survived':y_pred\n",
    "})\n",
    "\n",
    "submission.to_csv('./submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission=pd.read_csv('./submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
